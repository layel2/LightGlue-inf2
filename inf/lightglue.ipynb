{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb88d9b-84da-44a0-97f8-f28c87a98573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_neuronx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822e4f4a-4b91-43f6-8e9e-68e048d777a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3fdb7f-4cb3-4a3a-bf2a-36a2f067e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad89703-4e3e-4d56-9cb2-a14e35b016be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff028d8-1808-4507-a862-d2afde1bb77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import match_utils as mutils\n",
    "from lightglue import LightGlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79317272-7358-406d-9ae9-acc6a0fb9871",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher_cfg = {\n",
    "                 'name': 'lightglue',\n",
    "                 'input_dim': 256,\n",
    "                 'descriptor_dim': 256,\n",
    "                 'n_layers': 9,\n",
    "                 'num_heads': 4,\n",
    "                 'flash': True,\n",
    "                 'mp': False,\n",
    "                 'depth_confidence': 0.95,\n",
    "                 'width_confidence': 0.99,\n",
    "                 'filter_threshold': 0.1,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c848067-9d7b-405a-ba97-c88e15693133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/cvg/LightGlue/releases/download/v0.1_arxiv/disk_lightglue.pth\" to /home/ubuntu/.cache/torch/hub/checkpoints/disk_lightglue_v0-1_arxiv.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45.4M/45.4M [00:00<00:00, 283MB/s]\n"
     ]
    }
   ],
   "source": [
    "matcher = LightGlue(features=\"disk\", **matcher_cfg)\n",
    "matcher = matcher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe53027-559e-427c-86b0-73ed90c82e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import io\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)\n",
    "\n",
    "#contents = pickle.load(f) becomes...\n",
    "input_features = CPU_Unpickler(open(\"./lg-input.pkl\",\"rb\")).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0218bfa-5a02-4ca9-9956-e14d24792c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d4d690f-b273-41b7-8062-cd35abe91d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = matcher(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be8119af-c487-4fda-a14e-da749cb43ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1, -1, -1,  ..., -1, -1, -1]]),\n",
       " tensor([[84, 96, -1,  ..., -1, -1, -1]]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<CopySlices>),\n",
       " tensor([[9.6976e-01, 8.9296e-01, 0.0000e+00,  ..., 7.0294e-04, 9.8463e-02,\n",
       "          3.7209e-05]], grad_fn=<CopySlices>),\n",
       " tensor(7),\n",
       " tensor([[[   4,   10],\n",
       "          [  10,   28],\n",
       "          [  11,   26],\n",
       "          ...,\n",
       "          [1702, 2000],\n",
       "          [1707, 2001],\n",
       "          [1738, 2003]]]),\n",
       " tensor([[0.9636, 0.9931, 0.9956, 0.9301, 0.5737, 0.9851, 0.9873, 0.9719, 0.9744,\n",
       "          0.9943, 0.9872, 0.4076, 0.6476, 0.9939, 0.9129, 0.9596, 0.9950, 0.9772,\n",
       "          0.9971, 0.9291, 0.9875, 0.9925, 0.9827, 0.9764, 0.9692, 0.9698, 0.9923,\n",
       "          0.8318, 0.8930, 0.9660, 0.9365, 0.7401, 0.6620, 0.8455, 0.9108, 0.7441,\n",
       "          0.9597, 0.9587, 0.7494, 0.9528, 0.9286, 0.9875, 0.9952, 0.9961, 0.1068,\n",
       "          0.5394, 0.2414, 0.9365, 0.4869, 0.9560, 0.9921, 0.9304, 0.8763, 0.5236,\n",
       "          0.6264, 0.5472, 0.7242, 0.9974, 0.6551, 0.8399, 0.9618, 0.9873, 0.9606,\n",
       "          0.2072, 0.8363, 0.2450, 0.5934, 0.8409, 0.9828, 0.7387, 0.4140, 0.3524,\n",
       "          0.2303, 0.9968, 0.9923, 0.9983, 0.9977, 0.9984, 0.8174, 0.9906, 0.5518,\n",
       "          0.9974, 0.4676, 0.7333, 0.5143, 0.9766, 0.9951, 0.4574, 0.4464, 0.5517,\n",
       "          0.2706, 0.2078, 0.1783, 0.3515, 0.2576, 0.4818, 0.6223, 0.1507, 0.1330,\n",
       "          0.9766, 0.1581, 0.1583, 0.9990, 0.9984, 0.8582, 0.9958, 0.9834, 0.9859,\n",
       "          0.9920, 0.9301, 0.9908, 0.9981, 0.9906, 0.9975, 0.9451, 0.5175, 0.9930,\n",
       "          0.2264, 0.2072, 0.1021, 0.9775, 0.9814, 0.9714, 0.7374, 0.9958, 0.1185,\n",
       "          0.9990, 0.8900, 0.8944, 0.9771, 0.9930, 0.9913, 0.8847, 0.9995, 0.9842,\n",
       "          0.9882, 0.1874, 0.1093, 0.5031, 0.9918, 0.7853, 0.1892, 0.9639, 0.9990,\n",
       "          0.9885, 0.9854, 0.1182, 0.9824, 0.1924, 0.4614, 0.9953, 0.3099, 0.2957,\n",
       "          0.8744, 0.9995, 0.9974, 0.4102, 0.9982, 0.2706, 0.6412, 0.9966, 0.2175,\n",
       "          0.6626, 0.9896, 0.9958, 0.1006, 0.1413, 0.9816, 0.5914, 0.9975, 0.9990,\n",
       "          0.9893, 0.2797, 0.1933, 0.5068, 0.9993, 0.9991, 0.9967, 0.9987, 0.4710,\n",
       "          0.2637, 0.3159, 0.2832, 0.9832, 0.3160, 0.6983, 0.9789, 0.4655, 0.9990,\n",
       "          0.3611, 0.2644, 0.4910, 0.1198, 0.2260, 0.1600, 0.9940, 0.9722, 0.2457,\n",
       "          0.2179, 0.5149, 0.9848, 0.9598, 0.9953, 0.5769, 0.9251, 0.9545, 0.6453,\n",
       "          0.6192, 0.9030, 0.9431, 0.7581, 0.7172, 0.9272, 0.2479, 0.9928, 0.9924,\n",
       "          0.7800, 0.9877, 0.4123, 0.5702, 0.9973, 0.9828, 0.9988, 0.9984, 0.9985,\n",
       "          0.9880, 0.8726, 0.9562, 0.9942, 0.6247, 0.9987, 0.9991, 0.8974, 0.9936,\n",
       "          0.2097, 0.6345, 0.2578, 0.7663, 0.1189, 0.2760, 0.7393, 0.9629, 0.9962,\n",
       "          0.2749, 0.9460, 0.9972, 0.5848, 0.9827, 0.9387, 0.9992, 0.1617, 0.8032,\n",
       "          0.9329, 0.8789, 0.8308, 0.3291, 0.8715, 0.3107, 0.7771, 0.7968, 0.9620,\n",
       "          0.9310, 0.9796, 0.8915, 0.8049, 0.6365, 0.1757, 0.9979, 0.9984, 0.1698,\n",
       "          0.2571, 0.9946, 0.9954, 0.9746, 0.6849, 0.9992, 0.9710, 0.9788, 0.9982,\n",
       "          0.1793, 0.9753, 0.9810, 0.6412, 0.9992, 0.9991, 0.7469, 0.1664, 0.9971,\n",
       "          0.9993, 0.9984, 0.9404, 0.9992, 0.8136, 0.9474, 0.9831, 0.9997, 0.9831,\n",
       "          0.9069, 0.1102, 0.9922, 0.9215, 0.9405, 0.9500, 0.9978, 0.9993, 0.8905,\n",
       "          0.9997, 0.8679, 0.5195, 0.8700, 0.9995, 0.9993, 0.9995, 0.9990, 0.1536,\n",
       "          0.9817, 0.9814, 0.9365, 0.9849, 0.6319, 0.8667, 0.9212, 0.9950, 0.3457,\n",
       "          0.7807, 0.6441, 0.9995, 0.3632, 0.7667, 0.4506, 0.1838, 0.9691, 0.9799,\n",
       "          0.9893, 0.7393, 0.9974, 0.9990, 0.9991, 0.9987, 0.9610, 0.8420, 0.9689,\n",
       "          0.8043, 0.9995, 0.5475, 0.4565, 0.7242, 0.9993, 0.8069, 0.1956, 0.2649,\n",
       "          0.9982, 0.9991, 0.9968, 0.9845, 0.9811, 0.2733, 0.2725, 0.2679, 0.3709,\n",
       "          0.3925, 0.2120, 0.9786, 0.9981, 0.1036, 0.9759, 0.9998, 0.9499, 0.9799,\n",
       "          0.2579, 0.4843, 0.9846, 0.8977, 0.9338, 0.9942, 0.9810, 0.9155, 0.9997,\n",
       "          0.2621, 0.2095, 0.9973, 0.3223, 0.1965, 0.5504, 0.9915, 0.9986, 0.9968,\n",
       "          0.9954, 0.9993, 0.4738, 0.9870, 0.7749, 0.9995, 0.7773, 0.9806, 0.9682,\n",
       "          0.6189, 0.7338, 0.9846, 0.9864, 0.9773, 0.8177, 0.8351, 0.9821, 0.7456,\n",
       "          0.9622, 0.7797, 0.2274, 0.3085, 0.9741, 0.9904, 0.9820, 0.2702, 0.9336,\n",
       "          0.9479, 0.9902, 0.9197, 0.9111, 0.9995, 0.2014, 0.5841, 0.3940, 0.2371,\n",
       "          0.6980, 0.4175, 0.7986, 0.4061, 0.6393, 0.9997, 0.9986, 0.8014, 0.2907,\n",
       "          0.9492, 0.1060, 0.3451, 0.7829, 0.7971, 0.4066, 0.6549, 0.8297, 0.8477,\n",
       "          0.9556, 0.3766, 0.1079, 0.2470, 0.3998, 0.3824, 0.3791, 0.8108, 0.7647,\n",
       "          0.4455, 0.5886, 0.3477, 0.1849, 0.2566, 0.7087, 0.9374, 0.3704, 0.2759,\n",
       "          0.7200, 0.7218, 0.8796, 0.2730, 0.9861, 0.4517, 0.3193, 0.9820, 0.1009,\n",
       "          0.5886, 0.6260, 0.1399, 0.1212, 0.2041, 0.8646, 0.7643, 0.5634, 0.1733,\n",
       "          0.2207, 0.9328, 0.9921, 0.9915, 0.1069, 0.5063, 0.7854, 0.3675, 0.9913,\n",
       "          0.9980, 0.3739, 0.9992, 0.3544, 0.1082, 0.3655, 0.1192, 0.1177, 0.1173,\n",
       "          0.3995, 0.3416, 0.2487, 0.1597, 0.1910, 0.1404, 0.9919, 0.1586, 0.9980,\n",
       "          0.9975, 0.7484, 0.9978, 0.7382, 0.9959, 0.9423, 0.1513, 0.6732, 0.1044,\n",
       "          0.9825, 0.1034, 0.1323, 0.3002, 0.3518, 0.6386, 0.9949, 0.1916, 0.1510,\n",
       "          0.1721, 0.5203, 0.1378, 0.2390, 0.2824, 0.1422, 0.8628, 0.2021, 0.9036,\n",
       "          0.7681, 0.4577, 0.1719, 0.4326, 0.5990, 0.2378, 0.3564, 0.5275, 0.1625,\n",
       "          0.9709, 0.4131, 0.3026, 0.4600, 0.5176, 0.7323, 0.6849, 0.8955, 0.9418,\n",
       "          0.4990, 0.6554, 0.1562, 0.9684, 0.7149, 0.6549, 0.1152, 0.6815, 0.1824,\n",
       "          0.8886, 0.1284, 0.8829, 0.2947, 0.5757, 0.5508, 0.5158, 0.9230, 0.4295,\n",
       "          0.2296, 0.8158, 0.9235, 0.8087, 0.5263, 0.8515, 0.8189, 0.6091, 0.8778,\n",
       "          0.2466, 0.3855, 0.1998, 0.3695, 0.8166, 0.8963, 0.6592, 0.2064, 0.2122,\n",
       "          0.6219, 0.1072, 0.2278, 0.1520, 0.7407, 0.3776, 0.7769, 0.5613, 0.2348,\n",
       "          0.6237, 0.8377, 0.6064, 0.1570, 0.1260, 0.6254, 0.1226, 0.5103, 0.2043,\n",
       "          0.4132, 0.2512, 0.4646, 0.4956, 0.4278, 0.2663, 0.8818, 0.1788, 0.8934,\n",
       "          0.6881, 0.7940, 0.2111, 0.3857, 0.8012, 0.2504, 0.2763, 0.4080, 0.4660,\n",
       "          0.1110, 0.2581, 0.2415]], grad_fn=<StackBackward0>),\n",
       " tensor([[2, 3, 2,  ..., 2, 2, 3]]),\n",
       " tensor([[7, 7, 7,  ..., 7, 7, 7]])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4a6ce14-8edb-4af6-b750-a69a3e1c55c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/LightGlue/inf/../lightglue/lightglue.py:488: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert desc0.shape[-1] == self.conf.input_dim\n",
      "/home/ubuntu/LightGlue/inf/../lightglue/lightglue.py:489: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert desc1.shape[-1] == self.conf.input_dim\n",
      "/home/ubuntu/LightGlue/inf/../lightglue/lightglue.py:496: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  c = max(m, n)\n",
      "/home/ubuntu/LightGlue/inf/../lightglue/lightglue.py:530: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.check_if_stop(token0[..., :m, :], token1[..., :n, :], i, m + n):\n",
      "/home/ubuntu/LightGlue/inf/../lightglue/lightglue.py:532: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if do_point_pruning and desc0.shape[-2] > pruning_th:\n",
      "/home/ubuntu/LightGlue/inf/../lightglue/lightglue.py:540: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if do_point_pruning and desc1.shape[-2] > pruning_th:\n",
      "/home/ubuntu/LightGlue/inf/../lightglue/lightglue.py:583: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  \"stop\": torch.tensor(i + 1).to(device),\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/torch/jit/_trace.py:1065: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.\n",
      "  module._c._create_method_from_trace(\n"
     ]
    }
   ],
   "source": [
    "model_trace = torch.jit.trace(matcher, input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "288a5d7d-76b2-4544-8d65-711b2062535d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1, -1, -1,  ..., -1, -1, -1]]),\n",
       " tensor([[84, 96, -1,  ..., -1, -1, -1]]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<CopySlices>),\n",
       " tensor([[9.6976e-01, 8.9296e-01, 0.0000e+00,  ..., 7.0294e-04, 9.8463e-02,\n",
       "          3.7209e-05]], grad_fn=<CopySlices>),\n",
       " tensor(7),\n",
       " tensor([[[   4,   10],\n",
       "          [  10,   28],\n",
       "          [  11,   26],\n",
       "          ...,\n",
       "          [1702, 2000],\n",
       "          [1707, 2001],\n",
       "          [1738, 2003]]]),\n",
       " tensor([[0.9636, 0.9931, 0.9956, 0.9301, 0.5737, 0.9851, 0.9873, 0.9719, 0.9744,\n",
       "          0.9943, 0.9872, 0.4076, 0.6476, 0.9939, 0.9129, 0.9596, 0.9950, 0.9772,\n",
       "          0.9971, 0.9291, 0.9875, 0.9925, 0.9827, 0.9764, 0.9692, 0.9698, 0.9923,\n",
       "          0.8318, 0.8930, 0.9660, 0.9365, 0.7401, 0.6620, 0.8455, 0.9108, 0.7441,\n",
       "          0.9597, 0.9587, 0.7494, 0.9528, 0.9286, 0.9875, 0.9952, 0.9961, 0.1068,\n",
       "          0.5394, 0.2414, 0.9365, 0.4869, 0.9560, 0.9921, 0.9304, 0.8763, 0.5236,\n",
       "          0.6264, 0.5472, 0.7242, 0.9974, 0.6551, 0.8399, 0.9618, 0.9873, 0.9606,\n",
       "          0.2072, 0.8363, 0.2450, 0.5934, 0.8409, 0.9828, 0.7387, 0.4140, 0.3524,\n",
       "          0.2303, 0.9968, 0.9923, 0.9983, 0.9977, 0.9984, 0.8174, 0.9906, 0.5518,\n",
       "          0.9974, 0.4676, 0.7333, 0.5143, 0.9766, 0.9951, 0.4574, 0.4464, 0.5517,\n",
       "          0.2706, 0.2078, 0.1783, 0.3515, 0.2576, 0.4818, 0.6223, 0.1507, 0.1330,\n",
       "          0.9766, 0.1581, 0.1583, 0.9990, 0.9984, 0.8582, 0.9958, 0.9834, 0.9859,\n",
       "          0.9920, 0.9301, 0.9908, 0.9981, 0.9906, 0.9975, 0.9451, 0.5175, 0.9930,\n",
       "          0.2264, 0.2072, 0.1021, 0.9775, 0.9814, 0.9714, 0.7374, 0.9958, 0.1185,\n",
       "          0.9990, 0.8900, 0.8944, 0.9771, 0.9930, 0.9913, 0.8847, 0.9995, 0.9842,\n",
       "          0.9882, 0.1874, 0.1093, 0.5031, 0.9918, 0.7853, 0.1892, 0.9639, 0.9990,\n",
       "          0.9885, 0.9854, 0.1182, 0.9824, 0.1924, 0.4614, 0.9953, 0.3099, 0.2957,\n",
       "          0.8744, 0.9995, 0.9974, 0.4102, 0.9982, 0.2706, 0.6412, 0.9966, 0.2175,\n",
       "          0.6626, 0.9896, 0.9958, 0.1006, 0.1413, 0.9816, 0.5914, 0.9975, 0.9990,\n",
       "          0.9893, 0.2797, 0.1933, 0.5068, 0.9993, 0.9991, 0.9967, 0.9987, 0.4710,\n",
       "          0.2637, 0.3159, 0.2832, 0.9832, 0.3160, 0.6983, 0.9789, 0.4655, 0.9990,\n",
       "          0.3611, 0.2644, 0.4910, 0.1198, 0.2260, 0.1600, 0.9940, 0.9722, 0.2457,\n",
       "          0.2179, 0.5149, 0.9848, 0.9598, 0.9953, 0.5769, 0.9251, 0.9545, 0.6453,\n",
       "          0.6192, 0.9030, 0.9431, 0.7581, 0.7172, 0.9272, 0.2479, 0.9928, 0.9924,\n",
       "          0.7800, 0.9877, 0.4123, 0.5702, 0.9973, 0.9828, 0.9988, 0.9984, 0.9985,\n",
       "          0.9880, 0.8726, 0.9562, 0.9942, 0.6247, 0.9987, 0.9991, 0.8974, 0.9936,\n",
       "          0.2097, 0.6345, 0.2578, 0.7663, 0.1189, 0.2760, 0.7393, 0.9629, 0.9962,\n",
       "          0.2749, 0.9460, 0.9972, 0.5848, 0.9827, 0.9387, 0.9992, 0.1617, 0.8032,\n",
       "          0.9329, 0.8789, 0.8308, 0.3291, 0.8715, 0.3107, 0.7771, 0.7968, 0.9620,\n",
       "          0.9310, 0.9796, 0.8915, 0.8049, 0.6365, 0.1757, 0.9979, 0.9984, 0.1698,\n",
       "          0.2571, 0.9946, 0.9954, 0.9746, 0.6849, 0.9992, 0.9710, 0.9788, 0.9982,\n",
       "          0.1793, 0.9753, 0.9810, 0.6412, 0.9992, 0.9991, 0.7469, 0.1664, 0.9971,\n",
       "          0.9993, 0.9984, 0.9404, 0.9992, 0.8136, 0.9474, 0.9831, 0.9997, 0.9831,\n",
       "          0.9069, 0.1102, 0.9922, 0.9215, 0.9405, 0.9500, 0.9978, 0.9993, 0.8905,\n",
       "          0.9997, 0.8679, 0.5195, 0.8700, 0.9995, 0.9993, 0.9995, 0.9990, 0.1536,\n",
       "          0.9817, 0.9814, 0.9365, 0.9849, 0.6319, 0.8667, 0.9212, 0.9950, 0.3457,\n",
       "          0.7807, 0.6441, 0.9995, 0.3632, 0.7667, 0.4506, 0.1838, 0.9691, 0.9799,\n",
       "          0.9893, 0.7393, 0.9974, 0.9990, 0.9991, 0.9987, 0.9610, 0.8420, 0.9689,\n",
       "          0.8043, 0.9995, 0.5475, 0.4565, 0.7242, 0.9993, 0.8069, 0.1956, 0.2649,\n",
       "          0.9982, 0.9991, 0.9968, 0.9845, 0.9811, 0.2733, 0.2725, 0.2679, 0.3709,\n",
       "          0.3925, 0.2120, 0.9786, 0.9981, 0.1036, 0.9759, 0.9998, 0.9499, 0.9799,\n",
       "          0.2579, 0.4843, 0.9846, 0.8977, 0.9338, 0.9942, 0.9810, 0.9155, 0.9997,\n",
       "          0.2621, 0.2095, 0.9973, 0.3223, 0.1965, 0.5504, 0.9915, 0.9986, 0.9968,\n",
       "          0.9954, 0.9993, 0.4738, 0.9870, 0.7749, 0.9995, 0.7773, 0.9806, 0.9682,\n",
       "          0.6189, 0.7338, 0.9846, 0.9864, 0.9773, 0.8177, 0.8351, 0.9821, 0.7456,\n",
       "          0.9622, 0.7797, 0.2274, 0.3085, 0.9741, 0.9904, 0.9820, 0.2702, 0.9336,\n",
       "          0.9479, 0.9902, 0.9197, 0.9111, 0.9995, 0.2014, 0.5841, 0.3940, 0.2371,\n",
       "          0.6980, 0.4175, 0.7986, 0.4061, 0.6393, 0.9997, 0.9986, 0.8014, 0.2907,\n",
       "          0.9492, 0.1060, 0.3451, 0.7829, 0.7971, 0.4066, 0.6549, 0.8297, 0.8477,\n",
       "          0.9556, 0.3766, 0.1079, 0.2470, 0.3998, 0.3824, 0.3791, 0.8108, 0.7647,\n",
       "          0.4455, 0.5886, 0.3477, 0.1849, 0.2566, 0.7087, 0.9374, 0.3704, 0.2759,\n",
       "          0.7200, 0.7218, 0.8796, 0.2730, 0.9861, 0.4517, 0.3193, 0.9820, 0.1009,\n",
       "          0.5886, 0.6260, 0.1399, 0.1212, 0.2041, 0.8646, 0.7643, 0.5634, 0.1733,\n",
       "          0.2207, 0.9328, 0.9921, 0.9915, 0.1069, 0.5063, 0.7854, 0.3675, 0.9913,\n",
       "          0.9980, 0.3739, 0.9992, 0.3544, 0.1082, 0.3655, 0.1192, 0.1177, 0.1173,\n",
       "          0.3995, 0.3416, 0.2487, 0.1597, 0.1910, 0.1404, 0.9919, 0.1586, 0.9980,\n",
       "          0.9975, 0.7484, 0.9978, 0.7382, 0.9959, 0.9423, 0.1513, 0.6732, 0.1044,\n",
       "          0.9825, 0.1034, 0.1323, 0.3002, 0.3518, 0.6386, 0.9949, 0.1916, 0.1510,\n",
       "          0.1721, 0.5203, 0.1378, 0.2390, 0.2824, 0.1422, 0.8628, 0.2021, 0.9036,\n",
       "          0.7681, 0.4577, 0.1719, 0.4326, 0.5990, 0.2378, 0.3564, 0.5275, 0.1625,\n",
       "          0.9709, 0.4131, 0.3026, 0.4600, 0.5176, 0.7323, 0.6849, 0.8955, 0.9418,\n",
       "          0.4990, 0.6554, 0.1562, 0.9684, 0.7149, 0.6549, 0.1152, 0.6815, 0.1824,\n",
       "          0.8886, 0.1284, 0.8829, 0.2947, 0.5757, 0.5508, 0.5158, 0.9230, 0.4295,\n",
       "          0.2296, 0.8158, 0.9235, 0.8087, 0.5263, 0.8515, 0.8189, 0.6091, 0.8778,\n",
       "          0.2466, 0.3855, 0.1998, 0.3695, 0.8166, 0.8963, 0.6592, 0.2064, 0.2122,\n",
       "          0.6219, 0.1072, 0.2278, 0.1520, 0.7407, 0.3776, 0.7769, 0.5613, 0.2348,\n",
       "          0.6237, 0.8377, 0.6064, 0.1570, 0.1260, 0.6254, 0.1226, 0.5103, 0.2043,\n",
       "          0.4132, 0.2512, 0.4646, 0.4956, 0.4278, 0.2663, 0.8818, 0.1788, 0.8934,\n",
       "          0.6881, 0.7940, 0.2111, 0.3857, 0.8012, 0.2504, 0.2763, 0.4080, 0.4660,\n",
       "          0.1110, 0.2581, 0.2415]], grad_fn=<StackBackward0>),\n",
       " tensor([[2, 3, 2,  ..., 2, 2, 3]]),\n",
       " tensor([[7, 7, 7,  ..., 7, 7, 7]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trace(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98daf10-1ae7-42f7-8bcd-c9df1ea0cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-23 05:53:05.000289:  5676  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-01-23 05:53:05.000300:  5676  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.12.54.0+f631c2365/MODULE_2108354257835340671+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n",
      "2024-01-23 05:53:05.000565:  5676  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-01-23 05:53:05.000574:  5676  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.12.54.0+f631c2365/MODULE_8221219792448796712+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n",
      "2024-01-23 05:53:05.000794:  5676  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-01-23 05:53:05.000802:  5676  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.12.54.0+f631c2365/MODULE_5225604489184339909+d41d8cd9/model.neff. Exiting with a successfully compiled graph.\n",
      "2024-01-23 05:53:05.000990:  5676  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-01-23 05:53:05.000991:  5676  ERROR ||NEURON_CC_WRAPPER||: Got a cached failed neff at /var/tmp/neuron-compile-cache/neuronxcc-2.12.54.0+f631c2365/MODULE_7572268680822998320+d41d8cd9/model.neff. Will skip compilation, please set --retry_failed_compilation for recompilation: \n",
      " Failed compilation with ['neuronx-cc', 'compile', '--target=trn1', '--framework=XLA', '/tmp/ubuntu/neuroncc_compile_workdir/8b9b624b-eb6b-4e88-ba00-d1d5be32189b/model.MODULE_7572268680822998320+d41d8cd9.hlo_module.pb', '--output', '/tmp/ubuntu/neuroncc_compile_workdir/8b9b624b-eb6b-4e88-ba00-d1d5be32189b/model.MODULE_7572268680822998320+d41d8cd9.neff', '--verbose=35']: 2024-01-23T05:21:20Z [TEN404] (_gather.1446) Internal tensorizer error - Please open a support ticket at https://github.com/aws-neuron/aws-neuron-sdk/issues/new\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "model_neuron = torch_neuronx.trace(matcher, input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c51f5-215b-4223-8d77-e91dec275b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
